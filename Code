# installing

sudo apt-get update
sudo apt-get install python3-pip python3-opencv
pip3 install tflite-runtime

#converting yolov8 into tensorflow

from ultralytics import YOLO

model = YOLO('yolov8n.pt') 

model.export(format='saved_model')  

#saving to tensorflow lite 

import tensorflow as tf


saved_model_dir = 'yolov8n_saved_model'
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)


tflite_model = converter.convert()

with open('yolov8n.tflite', 'wb') as f:
    f.write(tflite_model)

#creating ros package

mkdir -p ~/catkin_ws/src
cd ~/catkin_ws/src
catkin_create_pkg yolov8_tflite_ros rospy std_msgs sensor_msgs
cd ~/catkin_ws
catkin_make

#MAin code

#!/usr/bin/env python3

import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from std_msgs.msg import String
import tflite_runtime.interpreter as tflite

class YOLOv8TFLiteNode:
    def __init__(self):
        rospy.init_node('yolov8_tflite_node', anonymous=True)
        self.bridge = CvBridge()
        self.image_sub = rospy.Subscriber('/camera/image_raw', Image, self.image_callback)
        self.detection_pub = rospy.Publisher('/detections', String, queue_size=10)
        
        # Load the TensorFlow Lite model
        self.interpreter = tflite.Interpreter(model_path='yolov8n.tflite')
        self.interpreter.allocate_tensors()
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()

    def image_callback(self, msg):
        try:
            # Convert ROS Image message to OpenCV image
            cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
            
            # Preprocess the image
            input_tensor = self.preprocess(cv_image)
            
            # Run inference
            self.interpreter.set_tensor(self.input_details[0]['index'], input_tensor)
            self.interpreter.invoke()
            detections = self.interpreter.get_tensor(self.output_details[0]['index'])
            
            # Postprocess detections
            self.postprocess(detections, cv_image)
        except Exception as e:
            rospy.logerr(e)

    def preprocess(self, image):
        # Resize and normalize the image
        image = cv2.resize(image, (640, 640))
        image = image.astype(np.float32) / 255.0
        image = np.expand_dims(image, axis=0)
        return image

    def postprocess(self, detections, image):
        # Process detections and publish results
        # This is a simplified example; you should implement proper post-processing
        detection_msg = String()
        detection_msg.data = str(detections)
        self.detection_pub.publish(detection_msg)

        # Optionally, visualize detections on the image
        cv2.imshow('YOLOv8 TFLite Detections', image)
        cv2.waitKey(1)

if __name__ == '__main__':
    try:
        node = YOLOv8TFLiteNode()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass
